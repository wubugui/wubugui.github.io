---
layout: post
title: "Reyes与Renderman"
modified:
categories: blog
excerpt:
tags: [渲染]
image:
feature:
date: 2017-04-16T08:08:50-04:00
---

# 开篇废话

Reyes已经相当古老了，2013年之后连Pixar也完全转入了基于MC的基于物理渲染，Reyes已成历史，但影响犹在，特别是在实时渲染上。

# Reyes[1]

## 目标问题

-   **模型复杂性**
要达到现实世界的真实度必须有很多复杂的几何体和纹理。
-   **模型多样性**
支持大量不同的几何图元。procedural models, fractals , graftals , and particle systems。
-   **着色复杂性**
可编程着色器是绝对必要的。
-   **最小化光线跟踪**
很多非本地光照效果都可以使用纹理来模拟。自然环境中环境很少有必须使用光线追踪。
-   **速度**
渲染动画，2小时，24帧，渲染速度非常关键。
-   **图像质量**
避免各种反走样：锯齿边，摩尔纹，temporal strobing，highlight aliasing。
-   **灵活性**
方便加入新的算法、技术。


## 设计原则

-   **自然坐标**
-   **向量化**
向量化，并行化，管线化
-   **Common representation**
使用一种最基本的几何对象来执行算法——micropolygons，这是一种平滑着色的subpixel-sized quadrilaterals。所有的着色、可见性都只在这上面执行。
-   **Locality**
Paging and data thrashing should be minimized.
a.Geometric locality.几何图元的计算不应该包含其他几何图元的引用。Procedural  models should be computed only once and should not be kept in their expanded form any longer than necessary.
b.纹理locality.只有被需要的纹理才在内存中，纹理应该只一次读离disk。
-   **线性化**
渲染时间应该和模型尺寸线性增长。
-   **允许大模型**
不应该有模型的尺寸限制。
-   **后门**
可以使用其他程序来渲染一些对象，用来随时加新的技术（虽然并不一定高效）。
-   **纹理映射**
纹理访问应该高效。一个表面可能有多个纹理。纹理是一种表现复杂材质特点的有力工具。

## 特点

Reyes的特点在于更多地把几何体曲线化而不是多边形化，以适应于渲染高质量的图形。

## 符号表示

为了更加明确概念，遂记之：
-   CAT：纹理的一致性访问，s、t分别是v/u的线性函数。
-   depth complexlty：每个采样点处的平均面数（可见和不可见的）。
-   dicing：把几何primitive转换为grids of micropolygons的过程。
-   displacement map：改变一个grid中点的位置的纹理。
-   $\epsilon$ plane：平行于hitter plane的表面，在eye的前面一点点。超越这个平面的透视计算都是不靠谱的。
-   eye space：正前方看着z，x在右，y下，右手系……
-   grid：micropolygon的二维数组。
-   geometric locality：计算每一个几何primitive的时候都不应该需要其他几何primitive的引用。
-   hitter plane：视椎的最小平面。zmin。
-   micropolygon：一个平坦着色的四边形，面积只有一个像素的大约1/4大小。他是最基本的几何对象。
-   screen space：透视空间。
-   yon plane：视椎的最远点。zmax。

##   算法描述

下面写下算法：
```cpp
Initialize the z buffer
for(each geometric primitive in the model)
{
    Read the primitive from the model file
    if(the primitive can be bounded)
    {
        bound the primitive in eye space
        if(the primitive is completely outside of the hitter-yon z range)
            cull it
        if(the primitive spans the epsilon plane and can be split)
            mark the primitive undiceable
        else
        {
            convert the bounds to screen space
            if(the bounds are completely outside the viewing frustum)
                cull the primitive
        }
    }
    if(the primitive can be diced)
    {
        dice the primitive into a grid of micropolygons
        compute normals and tangent vectors for the micropolygons in the grid
        shade the micropolygons in the grid
        break the grid into micropolygons
        for(each micropolygon)
        {
            bound the micropolygon in eye space
            if(the micropolygon is outside the hitter-yon range)
                cull it
            convert the micropolygon to screen space
            bound the micropolygon in screen space
            for(each sample point inside the screen space bound)
            {
                if(the sample point is inside the micropolygon)
                {
                    calculate the z of the micropolygon at the sample point by interpolation
                    if(the z at the sample point is less than the z in the buffer)
                    {
                        replace the sample in the buffer with this sample
                    }
                }
            }
        }
    }
    else
    {
    	split the primitive into other geometric primitives
    	put the new primitives at the head of the unread portion of the model file
    }
    filter the visible sample hits to produce pixels
    output the pixels
}                 
```
我的粗实现：
```cpp
void OLReyesFramework::world_end()
{
	hider->set_film(_state->top_options());
	hider->build_scene(_state->get_primitives(), _state->top_options());
	OLRayTraer::biud_view_scene(_state->get_primitives(),hider->get_cam());
	int bx = 4;
	int by = 4;
	hider->setup_bucket(bx,by);
	printf("Bucket : %d X %d \n",bx,by);
	OLBucket::set_dx_dy(hider->get_film().get_xres(),hider->get_film().get_yres());
	OLBucket* bucket;

	int thread_n = 0;
	while (bucket = hider->bucket_begin())
	{
		OLRenderContext *rc = new OLRenderContext();
		rc->disp_shader = nullptr;
		rc->surf_shader = nullptr;
		rc->bucket_self_ptr = bucket;
		rc->hider = hider;
		rc->framework = this;
		rc->thread_l = thread_n;
		OLBucket::t[thread_n] = std::thread(OLBucket::reyes,rc);
		thread_n++;
	}
	for (int i=0;i<16;i++)
	{
		OLBucket::t[i].join();
	}
	//todo : clear scene
	printf("skip mp num:%d\n",skip_mp);
	hider->save_image();
	RBDataCollector::get_inst()->output_floats();
}
/*
Buchect
*/
static void reyes(OLRenderContext* data)
	{
		OLPrimitive *p;
		OLHider* hider = data->hider;
		while ((p = data->bucket_self_ptr->first_prim()))
		{
			//bound and cull
			if (p->boundable())
			{
				//transform to eye space
				auto cam = hider->get_cam();
				auto bd = p->bound();

				//todo:estimate displacement shader to extend bounds
				//otherwise some mp will go out of the bucket after displacement.
#define TESTSIZE 16
				if(p->attri->displacement_shader)
					p->estimate_displacement_bound(bd,TESTSIZE);	
#undef TESTSIZE

				bd.aabb.transform(p->get_world_trans());
				RBMatrix m;
				cam.get_view_matrix(m);
				bd.aabb.transform(m);

				//cull near far
				if( (bd.aabb.min.y < cam.get_near_panel() && bd.aabb.max.y < cam.get_near_panel())||
					(bd.aabb.min.y>cam.get_far_panel()&&bd.aabb.max.y>cam.get_far_panel()))
				{
					delete p;
					continue;
				}
				cam.get_perspective_matrix(m);
				//set w to 1
				RBAABB2D bdb = bd.get_max_2daabb(m);
				bd.aabb.max.y = bd.aabb.min.y;
				bd.aabb.transform_aff(m);

				auto a = OLFramework::transform_to_perspective(data->bucket_self_ptr->ldx,data->bucket_self_ptr->ldy,hider->get_film().get_xres(),hider->get_film().get_yres());
				auto b = OLFramework::transform_to_perspective(data->bucket_self_ptr->rux,data->bucket_self_ptr->ruy,hider->get_film().get_xres(),hider->get_film().get_yres());
				RBAABB2D scr(b,a);
				if(!scr.check())
					printf("SCR check failed!\n");
				if (!bdb.intersection(scr))
				{
					delete p;
					continue;
				}
			}
			OLMicroPolygonGrid g;
			bool usplit(false), vsplit(false);
			if (p->diceable(g, *hider, usplit, vsplit))
			{
				if(g.x_dim<1||g.y_dim<1)
				{
					printf("x/y_dim<1 delete a primitive\n");
					delete p;
					continue;
				}

				//discard();
				p->dice(g,hider->get_cam(),OLPrimitive::E_DICE);
				if (!g.is_back_facing() && !g.trim())
				{
					if(p->attri->displacement_shader)
						g.displace(p->attri->displacement_shader);
					if(p->attri->surface_shader)
						g.shade(p->attri->surface_shader);
					hider->hide(g,data->bucket_self_ptr,data->thread_l);
				}
			}
			else if (p->splitable())
				p->split_multithread(data->bucket_self_ptr, usplit, vsplit);
			delete p;
		}
		hider->filetering(data->bucket_self_ptr);
		hider->save_image();
		printf("Thread %d done!\n",data->thread_l);
	}
```

一个现成的实现可以参考Pixie和Aqsis.

## 参考
-  [1] The Reyes Image Rendering Architecture , Robert L.Cook , Loren Carpenter , Edwin Catmull , Computer Graphics, Volume 21, Number 4, July 1987.

# Use Reyes

主要参考书籍是《Essential RenderMan》。更多的细节可以参考RenderMan Spec。

由于Prman总是要求我链接网络，而我在一种常年无网的状态下只能在本篇主要使用渲染器3Delight。有部分的渲染器则是开源的**Pixie**，直接下的win32编译版本。

## 说明
想要探索how，就必须先探索what。本篇主要目的并不是如何掌握Renderman，而是初探一些RenderMan的基本使用，追溯一些概念的由来。更多的实现要求细节参考Spec。

## RIB基本使用方法
```ruby
#transform.rib
Display "transform.tiff" "file" "rgba"
Projection "perspective"
WorldBegin
	Translate 0 -0.75 2.5

	TransformBegin
	Translate 0 1.3 0
	Scale 0.5 0.5 0.5
	Rotate -30 0 1 0

	Sphere 1 -1 1 360
	TransformBegin
		Translate 0 1.3 0
		TransformBegin
			Translate -0.75 0 0
			Scale 0.5 0.5 0.5
			Sphere 1 -1 1 360
		TransformEnd
	
		TransformBegin
			Translate 0.75 0 0
			Scale 0.5 0.5 0.5
			Sphere 1 -1 1 360
		TransformEnd
	TransformEnd
	
	TransformBegin
		Translate 0 0 -1.1
		Scale 0.3 0.3 0.5
		Sphere 1 -1 1 360
	TransformEnd
	
	TransformEnd
	
	Sphere 1 -1 1 360
WorldEnd
```
用法和pbrt差不多，渲染的时候直接输入渲染器渲染即可，Display是设置输出。
`TransformBegin/TransformEnd`代表成组transform，并且是可以层次tranform的。

Sphere的参数：半径，球的底、顶裁剪从而创建一个环（默认沿z轴，底是朝着底方向延伸符号是负的，顶是向着顶方向延伸）。

还有很多几何命令，就不多说了。

## Attribute
颜色透明度的使用
```ruby
#transform.rib
Display "transform.tiff" "file" "rgba"
Projection "perspective"
WorldBegin
	Translate 0 0 2
	Color [ 1 0 0 ]
	AttributeBegin
		Translate -0.25 0 0
		Color [ 0 1 0 ]
		Opacity [ 0.5 0.5 0.5 ]
		Sphere 1 -1 1 360
	AttributeEnd
	#This resets the color back to red
	AttributeBegin
		Translate 0.25 0 0
		Sphere 1 -1 1 360
	AttributeEnd
WorldEnd
```

![](~/13-57-58.jpg)

ShadingRate可以控制表面的点采样数，数字越大采样越少，但是在3delight上没什么效果。

Matte没有试验出预期效果，所以就直接copy下来了。
>Matte
When computer graphics are combined live action, a proxy object is sometimes placed in the CG scene to represent a real world object which will later be composited into place. This object should not appear in the final render, but will still obscure objects behind it. Such an object is known as a matte, and hence this property is specified by the Matte attribute. Matte 1 indicates that the object should be treated in this special way, while Matte 0 specifies a regularly rendered object.

Shaders
每个object都应用了自己的shader来描述表面。

## 相机

```ruby
#transform.rib
Display "transform.tiff" "file" "rgba"
Format 640 480 1.0
Clipping 0 15
PixelSamples 4 4
Exposure 1.0 2.2
Projection "perspective" "fov" [45]
WorldBegin
    Translate 0 0 3
    Translate 1 0 0
    Sphere 0.5 -0.5 0.5 360
WorldEnd
```
-   Format：长，宽，像素长宽比
-   Clipping：近裁距离，远裁距离
-   PixelSamples：水平采样数量，垂直采样数量（就是超级采样参数，这里是16倍采样）
-   Exposure：曝光补偿（线性乘因子），gamma矫正（**如果是直接输出到非线性播放设备上就要做gamma矫正，如果输出还需要更多的处理，保持线性，这里设置为1.0**）
-   Projection：设置透视，后面设置fov

## 光照
```ruby
LightSource
    [灯光类型] [自定义名称]
    "from" [位置坐标]
    #平行光有此项则忽略前面一项
    "to" [坐标位置]
    "intensity" [强度值]
    #聚光灯
    "coneangle" [val]
    "conedeltaangle" [val]
```
在Attribute中可以使用Illuminate命令通过自定义名字来开关灯光.
针对聚光灯上个图：

![](~/15-24-22.jpg)
```ruby
Surface “shadername” ...
LightSource “shadername” handle ...
Illuminate handle bool
LightSource “pointlight” 1
    “from” [ x y z ]
    “intensity” [ val ]
    “lightcolor” [ r g b ]
LightSource “distantlight” 2
    “to” [ x y z ]
    “intensity” [ val ]
    “lightcolor” [ r g b ]
LightSource “spotlight” 3
    “from” [ x y z ]
    “to” [ x y z ]
    “intensity” [ val ]
    “lightcolor” [ r g b ]
    “coneangle” [ angle ]
    “conedeltaangle” [angle]
LightSource “ambientlight” 4
    “intensity” [ val ]
    “lightcolor” [ r g b ]
```

## 标准表面类型
-   `Surface "constant"`最简单的着色，单一颜色，无明暗。
-   `Surface "Matte" "Ka" [val] "Kd [val]"`对环境光和漫反射建模的材质，Ka/kd分别为环境光和漫反射的权。设置为零意味着屏蔽。
-   `Surface "metal" "Ks" [val] "roughness" [val]`金属，Ks是高光亮度，roughness是高光尺寸。
-   `Surface "plastic" "Kd" [val] "Ks" [val]"specularcolor" [ r g b ]`这个材质名叫塑料，hold了漫反射高光高光颜色等属性。

```ruby
Surface "constant"
Surface "matte" "Ka"  [ 1 ]
"Kd" [ 1 ]
Surface "metal" "Ka"  [ 1 ]
"Ks" [ 1 ]
"roughness"  [0.1]
Surface "plastic"
"Ka" [ 1 ]
"Kd" [ 0.5 ]
"Ks" [ 0.5 ]
"roughness" [ 0.1 ]
"specularcolor" [ 1 1 1 ]
Surface "paintedplastic"
"Ka" [ 1 ]
"Kd" [ 0.5 ]
"Ks" [ 0.5 ]
"roughness" [0.1]
"specularcolor" [ 1 1 1 ]
"texturename" [ "" ]
```
...
到这里基本都入门了，后面的就不说了。下面开始说C API。

##  C API
RenderMan的C API和RIB命令是对应的，RIB的所有使用方式都同样适用于C API。
C API使得场景构建有了更多的灵活性。

![](~/02-48-00.jpg)
一个最简单的C API文件：
```cpp
/* min.c - a minimal C program to use RenderMan */
#include <ri.h>
int main(int argc, char  * argv[])
{
    RiBegin(RI_NULL);
        RiDisplay (“min.tiff”, “file”, “rgba”,RI_NULL);
        RiProjection (“perspective”,RI_NULL);
        RiWorldBegin();
            RiTranslate(0,0,2);
            RiSphere(1,−1,1,360,RI_NULL);
        RiWorldEnd();
    RiEnd();
    return 0;
}
```
下面例子是对应的**传参**例子：
```cpp
/* param.c - create a linear */
#include <ri.h>
int main(int argc, char  * argv[])
{
    RtPoint square[4]={{0,0,0},{1,0,0},{0,1,0},{1,1,0}};
    RtColor red={1,0,0};
    float fov=30;
    RiBegin(RI_NULL);
        RiDisplay ("param.tiff", "file", "rgba",RI_NULL);
        RiProjection("perspective","fov",&fov,RI_NULL);
        RiTranslate(-0.5,-0.5,3);
        RiWorldBegin();
            RiColor(red);
            RiPatch("bilinear","P",square,RI_NULL);
        RiWorldEnd();
    RiEnd();
return 0;
}
```
注意一点，所有参数最后都使用了`RI_NULL`来终结。

`RiDeclare`函数用于声明一个类型的参数。例如，有一个`myConstantSurface`shader需要一个`uniform color`类型的参数`customColor`。则使用下列代码：
```cpp
RiDeclare("customColo","uniform color");
RiSurface("myConstantSurface","customColor",red,RI_NULL);
//或者
RiSurface("myConstantSurface","uniform color customColor",red,RI_NULL);
```
光源的handle在API中用法如下：
```cpp
RtLightHandle theLight;
theLight = RiLightSource("pointlight","from",lightPos,RI_NULL);
```
有的图形，如例子，毛发使用rib文件来写是不现实的，使用API则非常简单。

## 着色

![](~/03-23-51.jpg)

## GI
RenderMan的一个设计目标是最小化光线跟踪，对于不需要跟踪就可以精确渲染的对象使用标准技术进行渲染，只有对确实需要光线跟踪对象才进行光线跟踪。

一个反射shader例子：
```cpp
surface reflect (
    float Ka = 1;
    float Kd = .2;
    float Ks = .7;
    float Kr = .3;
    float roughness = .1;
    color specularcolor = 1;)
    {
        normal Nf = faceforward (normalize(N),I);
        vector V = -normalize(I);
        color Ct;
        vector R = normalize(reflect(I,Nf));
        color Cr = trace(P,R);
        Ct = Cs;
        Oi = Os;
        Ci = Oi * ( Ct * (Ka*ambient() + Kd*diffuse(Nf)) +
        specularcolor * (Ks*specular(Nf,V,roughness) +
        Kr*Cr));
    }
```
注意`color Cr = trace(P,R);`一句会在R方向ray trace出一个颜色。
不那么抛光的表面就需要发射多根有轻微偏移的光线。然后把追踪结果blur一下。
这种情形下，renderman提供了gather sl。
```cpp
color Cr=0;
color Chit;
float samples=15;
vector R=normalize(reflect(I,Nf));
float hits=0;
gather("illuminance", P, R, radians(10), samples,"surface:Ci", Chit)
{
    Cr+=Chit;
    hits+=1;
}
else
{
    Cr+=color "rgb" (0.5,0.5,0.5);
    hits+=1;
}
Cr=Cr/hits;
```
gather在P处朝R方向以10为变换范围，发射samples根光线，被发射光线hit到的表面，将他的shader的Ci变量（事实上可以访问任何变量）拷贝到Chit中。下面的分支表示对于如果有hit的光线，执行语句，如果没有执行else语句。

# 设计参考

>本篇主要关注渲染器设计的前人经验，大部分内容都来自**Production Rendering Design and Implementation**和现有的渲染器实现，这里主要拆的是Pixie，也有拆一些其他的实现。
Object和Light结构可以在任何RiBegin和RiEnd之间创建。Object和Light都通过一个handle来标识。在Rib中使用的是一个unique identifier。

## 重访Reyes

前面有篇博客是读Reyes原论文的笔记，Reyes从发明到现在已经有几十年了，随着时代和需求的变迁他也在不断的进化之中。
一个Reyes架构的典型主要操作是：
**bound、split、dice、shade、hide.**
-   **bound**就是包围盒包围primitive。
-   **split**是分治法的一个实例。这里它的作用就是不断地分解一个primitive，使得目标的primitive可以dicing。另外，split需要保证子primitive在父primitive内。
-   **dice**把输入的high-order的primitive转换为像素尺寸级别的a grid of micropolygons。用通俗的话来说就是，分治法分而治之，split分到一定境界，就应该用dice来治了。
-   **shade**就是着色。首先是displacement着色，输出的是未着色grid，然后进行其他着色，着色结果是用户在shader中自定义的。着色进行在非透视空间，不能再透视空间，因为一般采用Gouraud着色需要向量之间的角度。
-   **hide**就是按照规则“隐藏”像素。最终hider将会直接把结果输出。



## Pixie实现

入口，由于renderman渲染器大多是经过渲染器API的调用来工作的，并且是通过解析rib，所以程序的真正渲染入口不能像传统的程序那样去找main或者winmain。根据renderman spec所描述，Renderman的API大多是在设置场景设置，真正call渲染是在worldend里面。在Pixie中正是这样。
戳开`RiWorldEnd`的CAPI会发现指向了`CRiInterface`的对应函数，这个只是个接口类，所以所有实现都是空的。在Pixie中，有两个类`CRendererContex`和`CRibOut`继承于`CRInterface`.前者就是渲染的主要执行者，所有的API都在这儿实现的。剩下一个是用来输出rib文件的，也就是把对应的场景参数转化成rib文件，然后通过这个文件送到一个Renderman兼容的渲染器进行渲染。里面函数的实现都是这个类似样子的：
```cpp
void    CRibOut::RiFrameAspectRatio(float aspect) 
{
	out("FrameAspectRatio %g\n",aspect);
}
```
真正的渲染过程是从`CRendererContext::RiWorldEnd`开始的。

```cpp
void    CRendererContext::RiWorldEnd(void) \
{
	// Render the frame
	CRenderer::renderFrame();

	// Cleanup the frame
	CRenderer::endFrame();
	
	// Restore the graphics state
	xformEnd();
	attributeEnd();
	optionEnd();
}
```
其中要关注的是`CRenderer::renderFrame();`，而这个函数看起来却是蛋疼的。
```cpp
///////////////////////////////////////////////////////////////////////
// Class				:	CRenderer
// Method				:	renderFrame
// Description			:	Render the frame
// Return Value			:	-
// Comments				:
void		CRenderer::renderFrame() {

	// Make sure we have a bounding hierarchy
	movvv(root->bmin,worldBmin);
	movvv(root->bmax,worldBmax);
	root->setChildren(contexts[0],root->children);
	numRenderedBuckets = 0;
	
	// Render the frame
	if (netNumServers != 0) {
		int				i;
		TThread			*threads;

		// Spawn the threads
		threads	=	(TThread *) alloca(netNumServers*sizeof(TThread));
		for (i=0;i<netNumServers;i++) {
			threads[i]	=	osCreateThread(serverDispatchThread,(void *) (intptr_t) i);
		}

		// Go to sleep until we're done
		for (i=0;i<netNumServers;i++) {
			osWaitThread(threads[i]);
		}

		// Send the ready to the servers to prepare them for the next frame
		for (i=0;i<netNumServers;i++) {
			T32	netBuffer;
			netBuffer.integer	=	NET_READY;
			rcSend(netServers[i],&netBuffer,sizeof(T32));
		}

	} else {
		int				i;
		TThread			*threads;

		// Let the client know that we're ready to render
		if (netClient != INVALID_SOCKET) {
			T32		netBuffer;

			netBuffer.integer	=	NET_READY;
			rcSend(netClient,&netBuffer,1*sizeof(T32));
		}
		
		// Spawn the threads
		threads	=	(TThread *) alloca(numThreads*sizeof(TThread));
		for (i=0;i<numThreads;i++) {
			threads[i]	=	osCreateThread(rendererDispatchThread,(void *) (intptr_t) i);
		}

		// Go to sleep until we're done
		for (i=0;i<numThreads;i++) {
			osWaitThread(threads[i]);
		}
	}
}

```
有很多代码在处理CS（第一个应该是客户端，第二个应该是服务器，具体的在这里不是重点，以后再看），剩下的在处理多线程，我们关心的东西就在线程函数之中。
```cpp
//...
		// Spawn the threads
		threads	=	(TThread *) alloca(numThreads*sizeof(TThread));
		for (i=0;i<numThreads;i++) {
			threads[i]	=	osCreateThread(rendererDispatchThread,(void *) (intptr_t) i);
		}
//...

//线程函数
///////////////////////////////////////////////////////////////////////
// Function				:	rendererThread
// Description			:	This thread is responsible for rendering
// Return Value			:
// Comments				:
static	TFunPrefix		rendererDispatchThread(void *w) {
	CRenderer::contexts[(uintptr_t) w]->renderingLoop();

	TFunReturn;
}		
```
找了半天终于发现一个有那么点意思的函数了，一戳发现有四个实现`CPhoton/CRaytracer/CReyes/CShow`，这四个实现对应不同的实现方式，我们现在主要关注的是Reyes。这些类都继承自`CShadingContext`，这类相当于一个渲染的接口，里面实现了一些线程安全的工程如随机数，“上下文”这是个大杂烩。
有用的东西在这儿：
```cpp
// Description			:	This is the rendering loop for the thread
void		CReyes::renderingLoop() {
	CRenderer::CJob	job;

#define computeExtends																									\
	bucketPixelLeft		=	currentXBucket*CRenderer::bucketWidth;														\
	bucketPixelTop		=	currentYBucket*CRenderer::bucketHeight;														\
	bucketPixelWidth	=	min(CRenderer::bucketWidth,		CRenderer::xPixels-bucketPixelLeft);						\
	bucketPixelHeight	=	min(CRenderer::bucketHeight,	CRenderer::yPixels-bucketPixelTop);							\
	tbucketLeft			=	bucketPixelLeft*CRenderer::pixelXsamples - CRenderer::xSampleOffset;						\
	tbucketTop			=	bucketPixelTop*CRenderer::pixelYsamples - CRenderer::ySampleOffset;							\
	tbucketRight		=	(bucketPixelLeft + bucketPixelWidth)*CRenderer::pixelXsamples - CRenderer::xSampleOffset;	\
	tbucketBottom		=	(bucketPixelTop + bucketPixelHeight)*CRenderer::pixelYsamples - CRenderer::ySampleOffset;

	// This is da loop
	while(TRUE) {
		// Get the job from the renderer
		CRenderer::dispatchJob(thread,job);
		// Process the job
		if (job.type == CRenderer::CJob::TERMINATE) {
			// End the context, cleanup of incomplete buckets
			// is in the destructor
			break;
		} else if (job.type == CRenderer::CJob::BUCKET) {
			const int	x	=	job.xBucket;
			const int	y	=	job.yBucket;
			assert(x < CRenderer::xBuckets);
			assert(y < CRenderer::yBuckets);
			// Skip the buckets reach the bucket we want
			while((currentXBucket != x) || (currentYBucket != y)) {
				computeExtends;
				skip();
			}
			// Render the bucket
			computeExtends;
			render();
		} else {
			error(CODE_BUG,"Invalid job for the hider\n");
			break;
		}
	}

#undef computeExtends

}
```
这里主要是分Bucket渲染。
其中`CRasterObject`是当前渲染的渲染Patch的信息，CBucket就是当前的Bucket，里面是要等待处理的Patch链表和一个当前正在处理的队列(*这可能是因为多线程准备的*).
```cpp
class CBucket 
{
public:
    // The list of objects waiting to be rendered
    CRasterObject *objects;
    //If this is not null, we're currently rendering this bucket
    CPqueue *queue;
};
```
需要注意的是，`CReyes`有三个虚函数
```cpp
	// The following functions must be overriden by the child rasterizer
	virtual	void				rasterBegin(int,int,int,int,int)			=	0;
	virtual	void				rasterDrawPrimitives(CRasterGrid *)			=	0;
	virtual	void				rasterEnd(float *,int)						=	0;
```
这三个虚函数只有两个**hider**实现过：
```cpp
class	CZbuffer : public CReyes , public COcclusionCuller;
class	CStochastic : public CReyes, public COcclusionCuller;
```
hider的作用就是把着色后的grid输出。
在`renderingLoop()`中调用了`render()`函数，所以这个东西在开始肯定被初始化为了上面两个hider中的其中一个。这些hider对应的函数为了防止那个文件太长都单独写在了一个头文件中。所以采用3个莫名其妙的文件:
-   Hiders/stochasticPrimitives.h
-   Hiders/zbufferPoint.h
-   Hiders/zbufferQuad.h

后面的split和dice这些过程都在`render()`函数中，其中dice每个函数都调用了object的dice，但是split有的包含在dice中，有的则在create函数中，还有的在shade中。其中基本基类`CSurface`的split函数是这个，但是方法名称却又是`shade`
```cpp
///////////////////////////////////////////////////////////////////////
// Class				:	CSurface
// Method				:	split
// Description			:	Split an object
// Return Value			:
// Comments				:
void    CSurface::shade(CShadingContext *context,int numRays,CRay **rays) 
{
	float	**varying	=	context->currentShadingState->varying;
	float	*u			=	varying[VARIABLE_U];
	float	*v			=	varying[VARIABLE_V];
	float	*time		=	varying[VARIABLE_TIME];
	float	*I			=	varying[VARIABLE_I];
	float	*du			=	varying[VARIABLE_DU];
	int		i;
	for (i=numRays;i>0;i--) {
		const CRay	*cRay	=	*rays++;
		*u++	=	cRay->u;						// The intersection u
		*v++	=	cRay->v;						// The intersection v
		*time++	=	cRay->time;						// The intersection time
		*du++	=	cRay->da*cRay->t + cRay->db;	// The ray differential
		mulvf(I,cRay->dir,cRay->t);					// Compute the I vector
		I		+=	3;
	}
	context->shade(this,numRays,1,SHADING_2D,0);
}

```

----------------------------------

## Pixie Hider([Ref](http://www.renderpixie.com/pixiewiki/Documentation/Hiders))
**raytrace**	As the name implies, this hider creates the final image using raytracing. This involves shooting bunch of rays for every pixel (defined by PixelSamples) and then filtering and summing the color of every ray (defined by PixelFilter).
**stochastic (hidden)**	(Default) This hider creates the final image using scan-line techniques very similar to Pixar's Reyes architecture. Every specified primitive is split into smaller primitives and deferred until needed. If the projected size of a subdivided primitive is small enough, a regular grid is sampled on the patch and the polygons in this grid are rendered using scan-line methods. Notice that a raytracer may need to keep the entire scene geometry in the memory in case a future ray can intersect them. On the other hand, the deferred and render-and-forget feature of this rendering algorithm allows it to keep a very small memory footprint
**zbuffer**	This hider is a stripped down version of Stochastic. It does not support motion blur, depth of field or transparency. If your scene does not involve these effects, this hider can generate an equal quality output with the Stochastic.
**photon**	This hider is used to compute photonmaps in a preprocessing step. This hider does not create an image. The renderer simply goes through the light sources defined in a scene and shoots photons.
New in 1.7.2 The photon hider supports dispersion of light.


这里为了更加清楚，再对Hider做一下解释，Hider原本的意思就是隐藏，也就是决定哪些点最终是可见的，所以我们可以这么说，这个东西的职责就是产生最终输出结果。在上面Pixie中我们看到他的Hider有raytrace，类Reyes，简化的类Reyes，以及photon。所以说，Hider的不同就代表了最终生成图像结果的算法不同，实际上Reyes也就是一种真实感图像生成架构。

实际上Hider有一种是在Reyes中定义的，就是说输入grid，输出着色后的像素。
这两个东西实际上，不太一样，但是确实还是类似的概念比较多，参考。

[Hidden surface determination](https://en.wikipedia.org/wiki/Hidden_surface_determination)
[Renderman Hider](http://renderman.pixar.com/view/hiders)

------------------------------


## Aqsis实现
Aqsis是一个兼容Renderman渲染器，目前还不支持多线程，所以阅读起来可能会比较方便。另外在Aqsis的文件中有一个newcore，是一个多线程renderman渲染器的原型，代码简单易读，注释也比较详细。
Aqsis渲染函数招法和前面的差不多，由于他目前还没有多线程，所以更加直接。最终的渲染Surface过程落在了`void CqImageBuffer::RenderImage()`中。但实际上的处理过程则是一个叫做`CqBucketProcessor* bucketProcessors[n];`的指针。这个`CqBucketProcessor`类就是实际Reyes的地方。

# 设计与实现

## RenderMan管线
需要注意在对mp求交的时候，要将mp的顶点有序化，否则可能会造成求交失败，使得渲染结果的很多区域丢失。

## 左手系y-up转换到z-up
由于我之前写东西都是使用y-up坐标，所以很多基础设备基本都是y-up的，并且因为开始写这个东西的时候，没有**统一好规范**导致系统的坐标和曲面解析的坐标出现了分歧。
在对曲面求P、DPdv、DPdu的时候都是在左手系z-up坐标中处理的，所以整个系统都采用了这种坐标系，开始是想把算出来的点和向量都直接转换一下转换到y-up，但这么说引起了一些问题：
-   首先是API直接设置的z-up坐标，所以API本身对外也是z-up的。如果在内部悄悄转换到y-up，会引起观察视角和预期的不一样。
-   相机获取矩阵的时候采用了y-up的方式来获取矩阵，这会引起transform的错误。
-   另外还有些AABB之类的变换会出现轴翻转的问题。
介于以上问题，于是就直接把真个坐标设置成了z-up。这样需要做的改变仅仅只是把原来的lookat之类的举证的yz位置对调就好了，其中在修正透视矩阵的时候最好对照原始的公式来修正矩阵，不然容易丢掉一个切变项。**注意：这里不是说矩阵本身有什么问题，矩阵本身和坐标系是无关的，这里只是设置矩阵的方式出现了问题。**
这里比较傻逼的是，因为开始的时候用的坐标系统uv和后来用的不一样，导致开始的时候坐标观察是在y正向朝着负向的，所以摄像机坐标就和世界坐标反转了，这就造成很多麻烦，以后有时间还要修正一下。这在下一节的最后点也有说明。

## AABB的转换
AABB在上述坐标系下转化是一个坑，一不注意就要掉进去。首先Primitive被Bound了之后，返回一个AABB，如果要transform或者什么之类的都要通过这个AABB来处理（因为有的参数曲面直接transform十几本没有办法的），一旦涉及到Transform AABB，问题就出来了：
-   AABB初始化要这么干
    ```cpp
      void reset()
      {
    	  this->min = RBVector3(MAX_F32,MAX_F32,MAX_F32);
    	  this->max = RBVector3(-(MAX_F32-1), -(MAX_F32-1), -(MAX_F32-1));
      }
    ```
-   Transform AABB不能只Transform两个端点，必须把所有顶点都解出来，一个一个地Transform，然后一个一个地include，否则可能出错，特别是透视和旋转的时候。
-   AABB的旋转将会造成AABB不断放大，同时会造成大小颠倒，必须要注意。

另外，当时图方便，**把摄像机朝向了-y方向，这是后面转换的根源，以后考虑把摄像机对着y方向，这样就更直观一些**。

## 双线性patch渲染三角形
把一个patch的顶点放到和另外两个定点的一条线上就成为了三角形。
![](~/1111.png)
但是这么做会出现一些问题。
DPdu(u,v) = a + (c-b)*v
DPdv(u,v) = b + (c-b)*u
在P[3]处求导，可以算出分别是两个导数c、d，反向的，叉乘为零。
所以就会出现这种情况：
![](~/sphere1.bmp)
这些红色的地方就是法线为零的地方。
所以还是要采用另外一种方法来渲染三角形：
当前的方法是，如果被渲染的是三角形，那么就通过定点来计算法线，因为平面上每个点的法线都是一个方向，而不是通过dpdu和dpdv来计算法线。

### 三角形
渲染三角形的困难还在于，巨大数量的三角形和单个三角形的细分平衡。在未来，为了优化三角形的渲染，可能会把处理三角形流程的部分流程按照实时渲染的方法来处理，这样以提升速度。


## Displacement shader

实现Displacement shader需要注意几点：
-   注意displacement之后出现的凹多边形。
当前是先hull，再求交，不过这么做可能比较耗时，不过不会出错。


 ！**PerlinDisplacer**

## dice
split的细分enough不是1/4个像素大小，1/4个像素大小应该是split出来的sub-patches dice后的micropolygon！split的足够小意味着大多数sub-patches都在一个单一的bucket中，或者在屏幕空间模拟细分后的mp大小到了1/4像素。
可以使用一个Abuffer来处理最后的采样链表
![](~/00-02-23.jpg)

![](~/00-04-48.jpg)
## Reyes已经被弃用了

![](~/00-10-01.jpg)
新的Prman有独立的PBR模式，参考：[renderman文档](https://renderman.pixar.com/resources/current/RenderMan/PxrLMMaterials.html)。

VCM积分器

## 参考
RibTools
appleseed
SmallVCM
[LuxRender](http://www.luxrender.net/en_GB/index)

## GI
### Brick
一个Brick由$N^3$个体素组成，每个体素保存了数据值，可能是颜色，法线，AO值等等。
下面是三个表面数据的稀疏brick map：
![](~/14-38-38.jpg)
下面是体积数据的三层dense brick map：
![](~/14-39-17.jpg)
**brick map的几个优点：**
-   独立于表面的表示
-   不需要uv，直接坐标就能参数化(为subdivision surfaces, implicit surfaces, and dense polygon meshes是非常糟心的)
-   自适应的分辨率，如果只有某个小区域有很高的细节，那就只有那个小区域有很多brick
-   便于mipmaping，tiling使得cache理想
-   用户可以手改精度

## Todo与已知困难
-   **split分界处定点被重复着色；法线在某些情况下出现了法线不垂直表面的情况参考参数：Sphere 人= 1.5 Pi -1 1 位置:(0,-1.7,0)**
-   **采样时双线性插值**
-   全面支持NURBS
-   全面支持三角网络
-   Disney shader是一个“catch all”shader，参数化，“principled” rather than strictly physical.
        -参考：[PxrDisney](https://renderman.pixar.com/resources/current/RenderMan/PxrDisney.html)/[Physically-Based Shading at Disney](https://disney-animation.s3.amazonaws.com/library/s2012_pbs_disney_brdf_notes_v2.pdf)
-   Displacement的Ray tracing  /[Ray Differentials and Multiresolution Geometry Caching for Distribution Ray Tracing in Complex Scenes](http://www.pixar.com/companyinfo/research/per/eg03.pdf)/桌面上的论文
-   [EnvDayLight](https://renderman.pixar.com/resources/current/RenderMan/PxrStdEnvDayLight.html)/[ref](http://www.cs.utah.edu/~shirley/papers/sunsky/)
-   [体积](https://renderman.pixar.com/resources/current/RenderMan/PxrVolume.html)
    [玻璃](https://renderman.pixar.com/resources/current/RenderMan/PxrGlass.html)
    [皮肤](https://renderman.pixar.com/resources/current/RenderMan/PxrSkin.html)
    [毛发](https://renderman.pixar.com/resources/current/RenderMan/PxrMarschnerHair.html)
-   [分层材质](https://renderman.pixar.com/resources/current/RenderMan/PxrLMMaterials.html)
